# -*- coding: utf-8 -*-
"""Digistar Bootcamp Regression - Home Pricing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LKKNwWaX_ZQmQ65hR8PGAwte1FdhDLlA
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Comment this if the data visualisations doesn't work on your side
# %matplotlib inline

from google.colab import drive
drive.mount('/content/drive/')

#Data source : Kaggle
#https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques

df = pd.read_csv("drive/MyDrive/kaggle_training/house_price/train.csv")

#Data checking
df.head(3)

df.shape

print(df.columns)

#Check Data Info
df.info()

#'SalePrice' is the column to predict
print(df['SalePrice'].describe())
plt.figure(figsize=(9, 8))
sns.distplot(df['SalePrice'], color='g', bins=100, hist_kws={'alpha': 0.4});

df.head(10)

sns.heatmap(df.isnull(),vmin=0, vmax=1)

#Check percentage info of missing data
missing_percentage = (df.isnull().sum() / len(df)) * 100
filtered_missing_percentage = missing_percentage[missing_percentage > 0]
print(filtered_missing_percentage)

df.set_index('Id', inplace=True)
df=df.drop(['Alley', 'MasVnrType', 'FireplaceQu', 'PoolQC','Fence','MiscFeature', ], axis='columns')
df.head(5)

sns.heatmap(df.isnull(),vmin=0, vmax=1)

df = df.dropna()

sns.heatmap(df.isnull(),vmin=0, vmax=1)

df.shape

df['LotArea'] = df['LotArea'].apply(lambda x: int(x.split(' ')[0]) if isinstance(x, str) else x)
df.head()

from sklearn.preprocessing import LabelEncoder,StandardScaler

# label encding
for col in df.columns:
    if df[col].dtype == 'object' or df[col].dtype=='category':
        df[col]=LabelEncoder().fit_transform(df[col])
df.head()

df.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8);

df.columns

df.isnull().sum()[df.isnull().sum() > 0].sort_values(ascending=False)
missing_data_cols = df.isnull().sum()[df.isnull().sum() > 0].index.tolist()
missing_data_cols

# find only categorical columns
cat_cols = df.select_dtypes(include='object').columns.tolist()
# find only numerical columns
num_cols = df.select_dtypes(exclude='object').columns.tolist()

print(f'Categorical Columns: {cat_cols}')
print(f'Numerical Columns: {num_cols}')

from sklearn.model_selection import train_test_split

y = df.SalePrice
X = df.drop(['SalePrice'], axis=1).select_dtypes(exclude=['object'])
train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.25)

from sklearn.linear_model import LinearRegression

model=LinearRegression()
model.fit(train_X, train_y)
pred = model.predict(test_X)
model.score(test_X,test_y)

# Import metrics.
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error


# Calculate and print R^2 score.
r2 = r2_score(test_y, pred)
print(f"R-squared: {r2:.8f}")

# Calculate and print MSE.
mse = mean_squared_error(test_y, pred)
print(f"Mean squared error: {mse:.8f}")


# Calculate and print RMSE.
rmse = mse ** 0.5
print(f"Root mean squared error: {rmse:.8f}")

# Calculate and print MEA.
mea = mean_absolute_error(test_y, pred)
print(f"Mean absolute error: {mea:.8f}")


# Calculate and print MAPE.
mape = mean_absolute_percentage_error(test_y, pred)
print(f"Mean absolute percentage error: {mape:.8f}")

from sklearn.linear_model import Lasso

model=Lasso(alpha=0.01)
model.fit(train_X, train_y)
pred = model.predict(test_X)
model.score(test_X,test_y)

# Import metrics.
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error


# Calculate and print R^2 score.
r2 = r2_score(test_y, pred)
print(f"R-squared: {r2:.8f}")

# Calculate and print MSE.
mse = mean_squared_error(test_y, pred)
print(f"Mean squared error: {mse:.8f}")


# Calculate and print RMSE.
rmse = mse ** 0.5
print(f"Root mean squared error: {rmse:.8f}")

# Calculate and print MEA.
mea = mean_absolute_error(test_y, pred)
print(f"Mean absolute error: {mea:.8f}")


# Calculate and print MAPE.
mape = mean_absolute_percentage_error(test_y, pred)
print(f"Mean absolute percentage error: {mape:.8f}")

from sklearn.linear_model import Ridge

model=Ridge(alpha=0.01)
model.fit(train_X, train_y)
pred = model.predict(test_X)
model.score(test_X,test_y)

# Import metrics.
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error


# Calculate and print R^2 score.
r2 = r2_score(test_y, pred)
print(f"R-squared: {r2:.8f}")

# Calculate and print MSE.
mse = mean_squared_error(test_y, pred)
print(f"Mean squared error: {mse:.8f}")


# Calculate and print RMSE.
rmse = mse ** 0.5
print(f"Root mean squared error: {rmse:.8f}")

# Calculate and print MEA.
mea = mean_absolute_error(test_y, pred)
print(f"Mean absolute error: {mea:.8f}")


# Calculate and print MAPE.
mape = mean_absolute_percentage_error(test_y, pred)
print(f"Mean absolute percentage error: {mape:.8f}")

from sklearn.ensemble import RandomForestRegressor

model=RandomForestRegressor()
model.fit(train_X, train_y)
pred = model.predict(test_X)
model.score(test_X,test_y)

# Import metrics.
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error


# Calculate and print R^2 score.
r2 = r2_score(test_y, pred)
print(f"R-squared: {r2:.8f}")

# Calculate and print MSE.
mse = mean_squared_error(test_y, pred)
print(f"Mean squared error: {mse:.8f}")


# Calculate and print RMSE.
rmse = mse ** 0.5
print(f"Root mean squared error: {rmse:.8f}")

# Calculate and print MEA.
mea = mean_absolute_error(test_y, pred)
print(f"Mean absolute error: {mea:.8f}")


# Calculate and print MAPE.
mape = mean_absolute_percentage_error(test_y, pred)
print(f"Mean absolute percentage error: {mape:.8f}")

from keras.callbacks import ModelCheckpoint, EarlyStopping
from keras.models import Sequential
from keras.layers import Dense, Activation, Flatten

callback = EarlyStopping(monitor='loss',patience=3)

model = Sequential()
model.add(Dense(1024, activation='relu', input_shape=[len(train_X.to_numpy()[0])]))
model.add(Dense(256, activation='relu'))
model.add(Dense(64, activation='relu'))
model.add(Dense(16, activation='relu'))
model.add(Dense(1))
#
model.compile(optimizer= 'adam', loss='mse', metrics=['mse'])
history = model.fit(train_X, train_y, epochs=200, verbose=0, batch_size=64, callbacks=[callback])

from sklearn.metrics import mean_squared_error as mse
pred = model.predict(test_X)
mse(pred, test_y)

from sklearn.metrics import mean_squared_error as mse
pred = model.predict(test_X)

# Import metrics.
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error


# Calculate and print R^2 score.
r2 = r2_score(test_y, pred)
print(f"R-squared: {r2:.8f}")

# Calculate and print MSE.
mse = mean_squared_error(test_y, pred)
print(f"Mean squared error: {mse:.8f}")


# Calculate and print RMSE.
rmse = mse ** 0.5
print(f"Root mean squared error: {rmse:.8f}")

# Calculate and print MEA.
mea = mean_absolute_error(test_y, pred)
print(f"Mean absolute error: {mea:.8f}")


# Calculate and print MAPE.
mape = mean_absolute_percentage_error(test_y, pred)
print(f"Mean absolute percentage error: {mape:.8f}")

